{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developmental-apollo",
   "metadata": {},
   "source": [
    "## Goal: pridict price\n",
    "note: airbnb deploys dynamic pricing. Here I assume that is not happening\n",
    "\n",
    "\n",
    "I intentionally to make the pipeline as less manual effort as possible. For text like columns, seg it with ckiptagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nasty-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethancy/airbnb_taipei/venv/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/ethancy/airbnb_taipei/venv/lib/python3.6/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "/Users/ethancy/airbnb_taipei/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ckiptagger import WS\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ws = WS(\"../../src/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/raw/listings_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-location",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5258, 74)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporated-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is numerical\n",
    "data['price'] = data['price'].str.replace('[$,]', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropCols(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # drop meaningless cols \n",
    "        X = X.drop([\n",
    "            'neighbourhood_group_cleansed','calendar_updated',\n",
    "            'calendar_last_scraped','license','bathrooms',\n",
    "            'id', 'listing_url', 'scrape_id', 'last_scraped'\n",
    "        ],axis='columns')\n",
    "        \n",
    "        # host upload info\n",
    "        X = X.drop(['host_picture_url','host_thumbnail_url'],axis='columns')\n",
    "        # host info\n",
    "        X = X.drop(['host_id','picture_url', 'host_url','host_name','host_about'],axis='columns')\n",
    "\n",
    "        # house geo\n",
    "        X = X.drop(['neighbourhood'],axis='columns')\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fixed-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess(BaseEstimator, TransformerMixin):\n",
    "    # transform all text, some irregular columns\n",
    "    def __init__(self):\n",
    "        self.text_cols = ['name', 'description','neighborhood_overview']\n",
    "#         self.special_col = ['bathrooms_text']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # text\n",
    "        X['text'] = X[self.text_cols].fillna('').apply(lambda x:\" \".join(x),axis='columns')\n",
    "        remove_pattern_list = [r\"<br(\\ )+\\/>\",\"<br>\",\"<b>\",\"<\\/b>\",\",\",'(',\")\",'/','[',']']\n",
    "        for pat in remove_pattern_list:\n",
    "            X['text'] = X['text'].str.replace(pat,\"\")\n",
    "        X['text_list'] = ws(X['text'])\n",
    "        for row in X.loc[X['text_list'].isnull(), 'text_list'].index:\n",
    "            X.at[row, 'text_list'] = []\n",
    "        X['text_list'] = X['text_list'].apply(lambda x:\" \".join(x))\n",
    "        X = X.drop(['text']+self.text_cols, axis='columns')\n",
    "        \n",
    "        X['shared_bath'] = X['bathrooms_text'].fillna('').str.lower().apply(lambda x: 'shared' in x)\n",
    "        X['bath_num'] = X['bathrooms_text'].str.extract(r'(\\d+(\\.\\d)?)')[0].astype(float)\n",
    "        X = X.drop('bathrooms_text',axis='columns')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        df = pd.DataFrame([X.values, y.values]).T\n",
    "        df.columns = ['cat','y']\n",
    "        df['y'] = df['y'].astype(float)\n",
    "        df['cat'] = df['cat'].fillna('nan')\n",
    "        self.enc_dict = df.groupby('cat')['y'].mean().to_dict()\n",
    "        self.ymean = df['y'].mean()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.fillna('nan').map(self.enc_dict).fillna(self.ymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "valid-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        self.enc_dict = X.value_counts().to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.map(self.enc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daily-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseCountVectorizer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.enc = CountVectorizer(max_features=20).fit(X)\n",
    "        self.feature_names = self.enc.get_feature_names()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.enc.transform(X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "younger-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEng(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_enc_method='target_enc', cat_list_enc_method='count+pca'):\n",
    "        self.cat_enc_method = cat_enc_method\n",
    "        self.cat_list_enc_method = cat_list_enc_method\n",
    "        \n",
    "        self.numerical_cols = [\n",
    "            'host_response_rate',\n",
    "           'host_acceptance_rate', 'host_total_listings_count',\n",
    "            'latitude','longitude',\n",
    "            'accommodates','bedrooms','beds',\n",
    "            'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
    "           'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "           'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "           'maximum_nights_avg_ntm', 'has_availability', 'availability_30',\n",
    "           'availability_60', 'availability_90', 'availability_365',\n",
    "           'number_of_reviews', 'number_of_reviews_ltm',\n",
    "            'number_of_reviews_l30d',\n",
    "             'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "            'review_scores_communication',\n",
    "            'review_scores_location','review_scores_value',\n",
    "            'calculated_host_listings_count',\n",
    "           'calculated_host_listings_count_entire_homes',\n",
    "           'calculated_host_listings_count_private_rooms',\n",
    "           'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n",
    "            'bath_num' # preprocessed\n",
    "        ]\n",
    "        \n",
    "        self.categorical_cols = [\n",
    "            'host_response_time','has_availability',\n",
    "            'host_is_superhost','host_neighbourhood','host_has_profile_pic','host_identity_verified',\n",
    "            'neighbourhood_cleansed','property_type','room_type',\n",
    "            'instant_bookable',\n",
    "            'shared_bath' # preprocessed\n",
    "        ]\n",
    "        self.categorical_list_cols = ['amenities','host_verifications','text_list']\n",
    "        self.date_cols = ['first_review','last_review','host_since']\n",
    "        \n",
    "\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.cat_list_enc_dict = {}\n",
    "        if self.cat_list_enc_method == 'count':\n",
    "            for col in self.categorical_list_cols:\n",
    "                self.cat_list_enc_dict[col] = Pipeline([\n",
    "                    ('count_vec', DenseCountVectorizer()),\n",
    "                ]).fit(X[col])\n",
    "        elif self.cat_list_enc_method == 'count+cluster':\n",
    "            for col in self.categorical_list_cols:\n",
    "                self.cat_list_enc_dict[col] = Pipeline([\n",
    "                    ('count_vec', DenseCountVectorizer()),\n",
    "                    ('cluster', KMeans())]\n",
    "                ).fit(X[col])\n",
    "        elif self.cat_list_enc_method == 'count+pca':\n",
    "            for col in self.categorical_list_cols:\n",
    "                self.cat_list_enc_dict[col] = Pipeline([\n",
    "                    ('count_vec', DenseCountVectorizer()),\n",
    "                    ('pca', PCA(n_components=10))\n",
    "                ]).fit(X[col])\n",
    "    \n",
    "        self.cat_enc_dict = {}\n",
    "        if self.cat_enc_method == 'label':\n",
    "            for col in self.categorical_cols:\n",
    "                cat_enc_dict[col] = LabelEncoder().fit(X[col])\n",
    "        elif self.cat_enc_method == 'one-hot':\n",
    "            for col in self.categorical_cols:\n",
    "                self.cat_enc_dict[col] = OneHotEncoder().fit(X[col])\n",
    "        elif self.cat_enc_method == 'target_enc':\n",
    "            for col in self.categorical_cols:\n",
    "                self.cat_enc_dict[col] = NumTargetEncoder().fit(X[col], y)\n",
    "        elif self.cat_list_enc_method == 'count_enc':\n",
    "            for col in self.categorical_cols:\n",
    "                self.cat_enc_dict[col] = CountEncoder().fit(X[col])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        print('cat')\n",
    "        print(X.shape)\n",
    "        for col in self.cat_enc_dict.keys():\n",
    "            X[col] = self.cat_enc_dict[col].transform(X[col])\n",
    "        \n",
    "        \n",
    "        print(X.shape)\n",
    "        print(\"cat list\")\n",
    "        for col in self.cat_list_enc_dict.keys():\n",
    "            X[col] = X[col].fillna('')\n",
    "            if self.cat_list_enc_method == 'count':\n",
    "                temp = pd.DataFrame(self.cat_list_enc_dict[col].transform(X[col]), columns = [col + \"_count_\"+ i for i in self.cat_list_enc_dict[col]['count_vec'].feature_names],index=X.index)\n",
    "                X = pd.concat([X,temp],axis='columns')\n",
    "            elif self.cat_list_enc_method == 'count+cluster':\n",
    "                X[col] = self.cat_list_enc_dict[col].predict(X[col])\n",
    "            elif self.cat_list_enc_method == 'count+pca':\n",
    "                temp = pd.DataFrame(self.cat_list_enc_dict[col].transform(X[col]), columns = [col + \"_pca_\"+ str(i) for i in range(self.cat_list_enc_dict[col]['pca'].n_components)],index=X.index)\n",
    "                X = pd.concat([X,temp],axis='columns')\n",
    "        X = X.drop(self.cat_list_enc_dict.keys(),axis='columns')\n",
    "        print(X.shape)\n",
    "        \n",
    "        X['host_location_is_local'] = X['host_location'].fillna('').apply(lambda x: any([keyword in x for keyword in ['taipei','Taipei','台北','臺北']]))\n",
    "        X['host_localtion_is_tw'] = X['host_location_is_local'] | X['host_location'].fillna('').apply(lambda x: any([keyword in x for keyword in ['taiwan','Taiwan','台灣','臺灣']]))\n",
    "        \n",
    "        for col in ['host_response_rate','host_acceptance_rate']:\n",
    "            X[col] = X[col].str.replace(\"%\",\"\").astype(float)\n",
    "        X = X.drop('host_location', axis='columns')\n",
    "        for col in self.date_cols:\n",
    "            X[col+'_duration']= (pd.to_datetime('today') - pd.to_datetime(X[col].fillna(pd.to_datetime('today')))).dt.days\n",
    "        X = X.drop(self.date_cols, axis='columns')\n",
    "        return X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "average-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('DropCols',DropCols()),\n",
    "    ('preprocess', Preprocess()),\n",
    "    ('fe', FeatureEng(cat_list_enc_method = 'count+pca'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "obvious-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('price',axis='columns'),\n",
    "    data['price'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "contemporary-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_ind = y_train[y_train<3000].index\n",
    "X_train = X_train.loc[valid_ind]\n",
    "y_train = y_train.loc[valid_ind]\n",
    "\n",
    "valid_ind = y_test[y_test<3000].index\n",
    "X_test2 = X_test.loc[valid_ind]\n",
    "y_test2 = y_test.loc[valid_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "healthy-excellence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "(3304, 55)\n",
      "(3304, 55)\n",
      "cat list\n",
      "(3304, 82)\n",
      "cat\n",
      "(1052, 55)\n",
      "(1052, 55)\n",
      "cat list\n",
      "(1052, 82)\n",
      "cat\n",
      "(836, 55)\n",
      "(836, 55)\n",
      "cat list\n",
      "(836, 82)\n",
      "CPU times: user 1h 10min 10s, sys: 6min 35s, total: 1h 16min 45s\n",
      "Wall time: 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_X_train = pipe.fit_transform(X_train, np.log1p(y_train))\n",
    "processed_X_test = pipe.transform(X_test)\n",
    "processed_X_test2 = pipe.transform(X_test2)\n",
    "processed_X_train.to_csv(\"../../data/processed/X_train.csv\", index=None)\n",
    "processed_X_test.to_csv(\"../../data/processed/X_test.csv\", index=None)\n",
    "processed_X_test2.to_csv(\"../../data/processed/X_test2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "varied-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_X_train = pd.read_csv(\"../../data/processed/X_train.csv\")\n",
    "# processed_X_test = pd.read_csv(\"../../data/processed/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "killing-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "failing-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_dict = {\n",
    "    'xgbr': {'model':XGBRegressor(), 'feat_imp_attr':'feature_importances_','param_grid':{'n_estimators':[30,100,200],'max_depth':[2,4,6], 'n_jobs':[-1]}},\n",
    "    'rf': {'model':RandomForestRegressor(), 'feat_imp_attr':'feature_importances_', 'param_grid':{'n_estimators':[50,100,200],'max_depth':[2,4,6]}, 'n_jobs':[-1]},\n",
    "    'elasticnet':{'model':ElasticNet(), 'feat_imp_attr':'coef_','param_grid':{'alpha':[1],'l1_ratio':[0.3, 0.5, 0.7]}},   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interior-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['best_param','feat_imp','train','test','test2'],index=regressor_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-regular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "settled-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 1.01 s, total: 3min 57s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for reg_method in regressor_dict.keys():\n",
    "    reg = GridSearchCV(regressor_dict[reg_method]['model'], param_grid=regressor_dict[reg_method]['param_grid'],cv=5)\n",
    "    reg.fit(processed_X_train,np.log1p(y_train))\n",
    "    res.loc[reg_method,'best_param'] = str(reg.best_params_)\n",
    "    res.loc[reg_method,'feat_imp'] = str(pd.Series(index=processed_X_train.columns.values,\n",
    "                                                   data=getattr(reg.best_estimator_,regressor_dict[reg_method]['feat_imp_attr'])).sort_values(ascending=False).iloc[:10]\n",
    "                                        )\n",
    "    res.loc[reg_method,'train'] = mean_absolute_error(np.expm1(reg.predict(processed_X_train)),y_train)\n",
    "    res.loc[reg_method,'test'] = mean_absolute_error(np.expm1(reg.predict(processed_X_test)),y_test)\n",
    "    res.loc[reg_method,'test2'] = mean_absolute_error(np.expm1(reg.predict(processed_X_test2)),y_test2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "gorgeous-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_param</th>\n",
       "      <th>feat_imp</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgbr</th>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 200, 'n_jobs'...</td>\n",
       "      <td>shared_bath                                   ...</td>\n",
       "      <td>109.016</td>\n",
       "      <td>1140.18</td>\n",
       "      <td>320.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 200}</td>\n",
       "      <td>shared_bath                                   ...</td>\n",
       "      <td>341.821</td>\n",
       "      <td>1236.57</td>\n",
       "      <td>370.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elasticnet</th>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>host_acceptance_rate      0.001697\\navailabili...</td>\n",
       "      <td>544.899</td>\n",
       "      <td>1475.19</td>\n",
       "      <td>543.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   best_param  \\\n",
       "xgbr        {'max_depth': 4, 'n_estimators': 200, 'n_jobs'...   \n",
       "rf                      {'max_depth': 6, 'n_estimators': 200}   \n",
       "elasticnet                      {'alpha': 1, 'l1_ratio': 0.3}   \n",
       "\n",
       "                                                     feat_imp    train  \\\n",
       "xgbr        shared_bath                                   ...  109.016   \n",
       "rf          shared_bath                                   ...  341.821   \n",
       "elasticnet  host_acceptance_rate      0.001697\\navailabili...  544.899   \n",
       "\n",
       "               test    test2  \n",
       "xgbr        1140.18  320.114  \n",
       "rf          1236.57  370.124  \n",
       "elasticnet  1475.19  543.731  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fantastic-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shared_bath                                     0.419830\\nproperty_type                                   0.043067\\naccommodates                                    0.031388\\nmaximum_minimum_nights                          0.029689\\nbedrooms                                        0.025813\\ncalculated_host_listings_count_entire_homes     0.024436\\nminimum_nights                                  0.016534\\ncalculated_host_listings_count_private_rooms    0.015710\\nroom_type                                       0.015201\\nbath_num                                        0.012644\\ndtype: float32'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc['xgbr','feat_imp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "antique-update",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shared_bath                                    0.418278\\naccommodates                                   0.152481\\nproperty_type                                  0.064276\\ncalculated_host_listings_count_entire_homes    0.047570\\nminimum_minimum_nights                         0.026607\\ntext_list_pca_4                                0.024621\\nhost_neighbourhood                             0.015466\\nminimum_nights_avg_ntm                         0.012873\\nnumber_of_reviews_ltm                          0.012788\\nbedrooms                                       0.012341\\ndtype: float64'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc['rf','feat_imp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "removable-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'host_acceptance_rate      0.001697\\navailability_90           0.000411\\nnumber_of_reviews         0.000343\\nlast_review_duration      0.000066\\nmaximum_nights            0.000065\\nfirst_review_duration     0.000006\\nhost_neighbourhood        0.000000\\nnumber_of_reviews_l30d   -0.000000\\nhost_is_superhost         0.000000\\nreview_scores_accuracy   -0.000000\\ndtype: float64'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc['elasticnet','feat_imp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-denver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
